{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics gradio openai --quiet\n"
      ],
      "metadata": {
        "id": "HldpXsiQBwk_"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "model = YOLO(\"yolov8n-seg.pt\")  # Lightweight segmentation model\n",
        "\n",
        "def analyze_rooftop(image):\n",
        "    results = model(image)\n",
        "    result_img = results[0].plot()  # Image with segmentation overlay\n",
        "    return Image.fromarray(result_img)\n"
      ],
      "metadata": {
        "id": "NPwcNk1YC5y2"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "gr.Interface(\n",
        "    fn=analyze_rooftop,\n",
        "    inputs=gr.Image(type=\"filepath\"),\n",
        "    outputs=\"image\",\n",
        "    title=\"AI Rooftop Solar Analyzer\"\n",
        ").launch()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "WTpguNmUDkyD",
        "outputId": "aded5659-0895-4145-ac5c-23ab33597db7"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://da4928c643de6533d6.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://da4928c643de6533d6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_solar_potential(area_m2):\n",
        "    panel_efficiency = 0.18\n",
        "    irradiance = 5.5  # kWh/m²/day\n",
        "    panel_power = panel_efficiency * irradiance * area_m2  # daily output in kWh\n",
        "    annual_energy = panel_power * 365  # annual output\n",
        "\n",
        "    cost_per_watt = 50  # ₹/W\n",
        "    total_power_kw = annual_energy / 365 / 5  # approximate kW system size\n",
        "    installation_cost = total_power_kw * 1000 * cost_per_watt\n",
        "\n",
        "    savings_per_year = annual_energy * 8  # ₹8 per kWh\n",
        "    roi_years = installation_cost / savings_per_year\n",
        "\n",
        "    return {\n",
        "        \"Usable Area (m²)\": round(area_m2, 2),\n",
        "        \"Estimated System Size (kW)\": round(total_power_kw, 2),\n",
        "        \"Annual Output (kWh)\": round(annual_energy, 2),\n",
        "        \"Estimated Installation Cost (₹)\": round(installation_cost, 2),\n",
        "        \"Estimated Savings/Year (₹)\": round(savings_per_year, 2),\n",
        "        \"Estimated Payback Period (years)\": round(roi_years, 2)\n",
        "    }\n"
      ],
      "metadata": {
        "id": "IOQt47n3Eq2y"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mock_solar_analysis(image, area_estimate_m2):\n",
        "    result = analyze_rooftop(image)\n",
        "    roi = estimate_solar_potential(area_estimate_m2)\n",
        "    return result, roi\n"
      ],
      "metadata": {
        "id": "DuZmWNeUEt0N"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(\n",
        "    fn=mock_solar_analysis,\n",
        "    inputs=[\n",
        "        gr.Image(type=\"filepath\", label=\"Upload Rooftop Image\"),\n",
        "        gr.Slider(10, 200, step=5, label=\"Estimated Rooftop Area (m²)\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Image(label=\"Rooftop Detection\"),\n",
        "        gr.JSON(label=\"Solar Analysis Report\")\n",
        "    ],\n",
        "    title=\"AI-Powered Rooftop Solar Analyzer\"\n",
        ").launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "p1W0LlhpEvbl",
        "outputId": "addca2f8-4e99-4a53-8873-842bb96fb448"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://04ca9b7a58ed2bebfc.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://04ca9b7a58ed2bebfc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rooftop_area_from_mask(results, pixels_per_meter=50):\n",
        "    \"\"\"\n",
        "    Estimate rooftop area from segmentation mask.\n",
        "    pixels_per_meter: assumed scale, 50px ~ 1 meter (adjust as needed)\n",
        "    \"\"\"\n",
        "    mask = results[0].masks.data[0].cpu().numpy()  # get the first mask\n",
        "    area_pixels = np.sum(mask)\n",
        "    area_m2 = area_pixels / (pixels_per_meter ** 2)\n",
        "    return area_m2\n"
      ],
      "metadata": {
        "id": "f0JRks8nFLiu"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def full_rooftop_analysis(image):\n",
        "    results = model(image)\n",
        "    result_img = results[0].plot()\n",
        "\n",
        "    try:\n",
        "        area_m2 = get_rooftop_area_from_mask(results)\n",
        "    except Exception as e:\n",
        "        return Image.fromarray(result_img), {\"error\": f\"Rooftop not detected or mask failed: {e}\"}\n",
        "\n",
        "    report = estimate_solar_potential(area_m2)\n",
        "    return Image.fromarray(result_img), report\n"
      ],
      "metadata": {
        "id": "cJRTk1GEFMeG"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(\n",
        "    fn=full_rooftop_analysis,\n",
        "    inputs=gr.Image(type=\"filepath\", label=\"Upload Rooftop Image\"),\n",
        "    outputs=[\n",
        "        gr.Image(label=\"Rooftop Detection\"),\n",
        "        gr.JSON(label=\"Solar Analysis Report\")\n",
        "    ],\n",
        "    title=\"AI-Powered Rooftop Solar Analyzer (Auto Area Detection)\"\n",
        ").launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "FDbvGzxCFPCw",
        "outputId": "edef3375-0ccf-40eb-c2b1-699d012ee2f4"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://78fe964c92eb5e791d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://78fe964c92eb5e791d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers accelerate --quiet\n"
      ],
      "metadata": {
        "id": "jdIwhAFyQcgp"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9etuU1llQfxo",
        "outputId": "b29f95b2-7643-48c0-c8bd-fa07b059984c"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def offline_llm_summary(roi_dict):\n",
        "    prompt = f\"\"\"\n",
        "You are a smart assistant for solar energy advice.\n",
        "\n",
        "A user has uploaded a satellite image of their rooftop. Based on the analysis, generate a short, clear, and friendly report describing the rooftop's solar installation potential. Include insights on the system size, energy output, installation cost, savings, and the return on investment.\n",
        "\n",
        "Use this data:\n",
        "- Rooftop Area: {roi_dict['Usable Area (m²)']} m²\n",
        "- Estimated System Size: {roi_dict['Estimated System Size (kW)']} kW\n",
        "- Annual Output: {roi_dict['Annual Output (kWh)']} kWh\n",
        "- Installation Cost: ₹{roi_dict['Estimated Installation Cost (₹)']}\n",
        "- Yearly Savings: ₹{roi_dict['Estimated Savings/Year (₹)']}\n",
        "- Payback Period: {roi_dict['Estimated Payback Period (years)']} years\n",
        "\n",
        "Keep it under 100 words and encourage solar adoption if feasible.\n",
        "Response:\n",
        "\"\"\"\n",
        "    output = generator(prompt, max_new_tokens=120, temperature=0.7)[0][\"generated_text\"]\n",
        "    return output.split(\"Response:\")[-1].strip()\n"
      ],
      "metadata": {
        "id": "LM6X2fMqQmyP"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def full_rooftop_analysis_with_local_llm(image):\n",
        "    results = model(image)\n",
        "    result_img = results[0].plot()\n",
        "\n",
        "    try:\n",
        "        area_m2 = get_rooftop_area_from_mask(results)\n",
        "        report = estimate_solar_potential(area_m2)\n",
        "        summary = offline_llm_summary(report)\n",
        "        return Image.fromarray(result_img), report, summary\n",
        "    except Exception as e:\n",
        "        return Image.fromarray(result_img), {\"error\": str(e)}, \"LLM summary failed.\"\n"
      ],
      "metadata": {
        "id": "hc9_5vs8Qoh2"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(\n",
        "    fn=full_rooftop_analysis_with_local_llm,\n",
        "    inputs=gr.Image(type=\"filepath\", label=\"Upload Rooftop Image\"),\n",
        "    outputs=[\n",
        "        gr.Image(label=\"Rooftop Detection\"),\n",
        "        gr.JSON(label=\"Solar Analysis Report\"),\n",
        "        gr.Textbox(label=\"LLM Summary (Offline)\")\n",
        "    ],\n",
        "    title=\"AI Rooftop Solar Analyzer (Offline LLM)\"\n",
        ").launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "JFPF_s5bQpUv",
        "outputId": "bd3c9cdc-594a-4df7-eb57-930f259d345d"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://131b31a29e9e61ac54.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://131b31a29e9e61ac54.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/facebookresearch/segment-anything.git\n",
        "!pip install opencv-python matplotlib --quiet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FILvSMYoTB1R",
        "outputId": "75f6e2b3-dcb7-4ced-cb9e-a8e1da953397"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/segment-anything.git\n",
            "  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-ote072tz\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-ote072tz\n",
            "  Resolved https://github.com/facebookresearch/segment-anything.git to commit dca509fe793f601edb92606367a655c15ac00fdf\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Create directory and download the model\n",
        "os.makedirs(\"sam_weights\", exist_ok=True)\n",
        "\n",
        "!wget -O sam_weights/sam_vit_h.pth https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xT2a4uZSTFWI",
        "outputId": "005dc14d-887a-41d4-9318-3820ec7aafb8"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-26 17:00:42--  https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.226.210.15, 13.226.210.25, 13.226.210.111, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.226.210.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2564550879 (2.4G) [binary/octet-stream]\n",
            "Saving to: ‘sam_weights/sam_vit_h.pth’\n",
            "\n",
            "sam_weights/sam_vit 100%[===================>]   2.39G  70.5MB/s    in 41s     \n",
            "\n",
            "2025-05-26 17:01:23 (59.1 MB/s) - ‘sam_weights/sam_vit_h.pth’ saved [2564550879/2564550879]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load SAM\n",
        "sam = sam_model_registry[\"vit_h\"](checkpoint=\"sam_weights/sam_vit_h.pth\")\n",
        "sam.to(\"cuda\")\n",
        "\n",
        "# Mask generator\n",
        "mask_generator = SamAutomaticMaskGenerator(sam)\n"
      ],
      "metadata": {
        "id": "1c5pVXk7TOlA"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_rooftop_with_sam(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    masks = mask_generator.generate(image_rgb)\n",
        "\n",
        "    # Combine all SAM masks into one binary mask\n",
        "    combined_mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
        "    for mask in masks:\n",
        "        combined_mask = np.logical_or(combined_mask, mask[\"segmentation\"])\n",
        "\n",
        "    combined_mask = combined_mask.astype(np.uint8)\n",
        "\n",
        "    # Create colored overlay on the image\n",
        "    overlay = image_rgb.copy()\n",
        "    overlay[combined_mask == 1] = [0, 255, 0]  # green mask for rooftop\n",
        "\n",
        "    # Blend original + mask for visibility\n",
        "    alpha = 0.5\n",
        "    blended = cv2.addWeighted(image_rgb, 1 - alpha, overlay, alpha, 0)\n",
        "\n",
        "    # Return visual + mask area (pixel count)\n",
        "    return Image.fromarray(blended), np.sum(combined_mask)\n"
      ],
      "metadata": {
        "id": "qof3JnlqTRHv"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def area_from_sam_mask(pixel_count, pixels_per_meter=50):\n",
        "    return pixel_count / (pixels_per_meter ** 2)\n"
      ],
      "metadata": {
        "id": "1KS3PnzzTUTJ"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def full_rooftop_analysis_with_sam(image_path):\n",
        "    masked_image, pixel_count = segment_rooftop_with_sam(image_path)\n",
        "    area_m2 = area_from_sam_mask(pixel_count)\n",
        "    report = estimate_solar_potential(area_m2)\n",
        "    summary = offline_llm_summary(report)\n",
        "\n",
        "    return masked_image, report, summary\n"
      ],
      "metadata": {
        "id": "8F-kzpoqTWyh"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(\n",
        "    fn=full_rooftop_analysis_with_sam,\n",
        "    inputs=gr.Image(type=\"filepath\", label=\"Upload Satellite Rooftop Image\"),\n",
        "    outputs=[\n",
        "        gr.Image(label=\"Rooftop Segmentation (SAM)\"),\n",
        "        gr.JSON(label=\"Solar Analysis Report\"),\n",
        "        gr.Textbox(label=\"LLM Summary (Offline)\")\n",
        "    ],\n",
        "    title=\"SAM-Powered Rooftop Solar Analyzer\"\n",
        ").launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "KDQSyJaJTYdw",
        "outputId": "6333a81a-5cca-4e09-b5dd-a8396c6da4cc"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://8cc39f73d8b9745593.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8cc39f73d8b9745593.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_rooftop_with_clean_overlay(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    masks = mask_generator.generate(image_rgb)\n",
        "\n",
        "    # Filter + sort largest masks\n",
        "    masks = sorted(masks, key=lambda x: np.sum(x[\"segmentation\"]), reverse=True)\n",
        "    masks = [m for m in masks if np.sum(m[\"segmentation\"]) > 500][:30]  # max 30 big masks\n",
        "\n",
        "    annotated_img = image_rgb.copy()\n",
        "    total_px = 0\n",
        "\n",
        "    for mask in masks:\n",
        "        seg = mask['segmentation'].astype(np.uint8)\n",
        "        area_px = np.sum(seg)\n",
        "        total_px += area_px\n",
        "\n",
        "        overlay = np.zeros_like(image_rgb)\n",
        "        overlay[seg == 1] = (0, 255, 255)\n",
        "\n",
        "        annotated_img = cv2.addWeighted(annotated_img, 1, overlay, 0.4, 0)\n",
        "\n",
        "        x, y, w, h = cv2.boundingRect(seg)\n",
        "        area_m2 = area_px / (50 ** 2)\n",
        "        cv2.rectangle(annotated_img, (x, y), (x + w, y + h), (255, 255, 255), 1)\n",
        "        cv2.putText(annotated_img, f\"{area_m2:.2f} m²\", (x, y - 5),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "    return Image.fromarray(annotated_img), total_px\n"
      ],
      "metadata": {
        "id": "AvyMb1XIU3_q"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def full_rooftop_analysis_with_visual_overlay(image_path):\n",
        "    annotated_img, total_px = segment_rooftop_with_clean_overlay(image_path)\n",
        "    area_m2 = area_from_sam_mask(total_px)\n",
        "    report = estimate_solar_potential(area_m2)\n",
        "    summary = offline_llm_summary(report)\n",
        "\n",
        "    return annotated_img, report, summary\n"
      ],
      "metadata": {
        "id": "pwrOZ0mwU6rx"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(\n",
        "    fn=full_rooftop_analysis_with_visual_overlay,\n",
        "    inputs=gr.Image(type=\"filepath\", label=\"Upload Satellite Image\"),\n",
        "    outputs=[\n",
        "        gr.Image(label=\"Rooftop Detection + Area\"),\n",
        "        gr.JSON(label=\"Solar Report\"),\n",
        "        gr.Textbox(label=\"LLM Summary\")\n",
        "    ],\n",
        "    title=\"Solar Analyzer with Visual Area Overlay\"\n",
        ").launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "2HaO6NW6U8Eq",
        "outputId": "1f8bdfa0-1e50-49c5-d338-60158a616838"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://8cc00001530778bf16.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8cc00001530778bf16.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    }
  ]
}